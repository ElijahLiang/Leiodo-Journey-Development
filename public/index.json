[{"content":"Introduction This project represents a solitary yet enlightening journey into Embodied AI. Starting in November 2025, I attempted to drive an NPC using LLMs within Unity. What began as a simple experiment evolved into a deep exploration of how AI can truly \u0026ldquo;see\u0026rdquo; and understand its environment.\nThe Beginning: Heuristic Approaches My initial approach relied on heuristic hacks like Raycast for perception:\n// Traditional approach - Raycast-based perception RaycastHit hit; if (Physics.Raycast(transform.position, transform.forward, out hit, maxDistance)) { string objectName = hit.collider.gameObject.name; // Convert to text description for LLM } This resulted in:\n❌ Poor navigation ❌ Lack of true spatial awareness ❌ Brittle behavior trees I briefly detoured into ML-Agents, only to realize that reinforcement learning created a \u0026ldquo;conditioned subject\u0026rdquo; — functional but incapable of the generalization I sought.\nThe Breakthrough: Vision-Language Models The breakthrough came in December with the integration of Vision-Language Models (VLM). By connecting a first-person camera to Qwen-VL-Plus, the agent gained the ability to truly \u0026ldquo;see\u0026rdquo;:\nP C E a R m C e E r P a T I → O N R e P n I d P e E r L T I e N x E t : u r e → P N G B y t e s → B a s e 6 4 → V L M A P I → S c e n e D e s c r i p t i o n The VLM doesn\u0026rsquo;t just detect objects — it understands spatial relationships, context, and even subtle visual cues.\nThe Current State: End-to-End Loop In January 2026, I successfully achieved an end-to-end loop:\nPerceive: VLM interprets first-person visual input Reason: LLM processes scene description with context Act: Agent executes specific behaviors Express: Emotional responses through animations Architecture Overview ┌ │ │ └ ─ ─ ─ ─ ─ U 5 ─ ─ n 1 ─ ─ i 2 ─ ─ t x ─ ─ y 5 ─ ─ 1 ─ ─ C 2 ─ ─ a ─ ─ m P ─ ─ e N ─ ─ r G ─ ─ a ─ ─ ─ ─ ─ ─ ─ ┐ │ │ ┘ ─ ─ ─ ▶ ┌ │ │ └ ─ ─ ─ ─ ─ Q S ─ ─ w c ─ ─ e e ─ ─ n n ─ ─ - e ─ ─ V ─ ─ L A ─ ─ n ─ ─ ( a ─ ─ V l ─ ─ L y ─ ─ M s ─ ─ ) i ─ ─ s ─ ─ ─ ─ ─ ┐ │ ┘ ─ │ ─ ─ ▶ ┌ │ │ │ └ ┌ │ └ ─ ─ ─ │ ─ ─ ─ ─ ─ ─ A G S ─ ─ D ─ ─ c O T ─ ─ e D ─ ─ t _ O ─ ─ e e ─ ─ i T P ─ ─ p c ─ ─ o O ─ ─ S i ─ ─ n E ─ ─ e s ─ │ ▼ ─ E M ─ ─ e i ─ ─ L X O ─ ─ k o ─ ─ a P T ─ ─ n ─ ─ y L I ─ ─ L ─ ─ e O O ─ ─ L ─ ─ r R N ─ ─ M ─ ─ E ─ ─ ─ ─ ─ ─ ─ ┐ │ │ │ ┘ ┐ │ ┘ │ Key Learnings 1. Perception is Everything Without true visual understanding, AI agents are fundamentally limited. VLMs bridge the gap between raw pixels and semantic understanding.\n2. Memory Matters The agent maintains three types of memory:\nEnvironmental: Known objects, visited places Dialogue: Conversation history Goals: Current task, sub-goals 3. Emergent Behaviors With proper perception, behaviors emerge naturally:\nCuriosity-driven exploration Memory-informed avoidance Context-aware responses What\u0026rsquo;s Next While hardware constraints currently necessitate a script-driven action layer (preventing a full VLA implementation), this prototype validates the core architecture. Future explorations include:\nWorld Models: Predicting future states Sim2Real: Transferring to physical robots Multi-agent: Collaborative AI behaviors Conclusion This journey taught me that the key to intelligent agents isn\u0026rsquo;t more complex behavior trees — it\u0026rsquo;s giving them the ability to truly perceive and understand their world. The combination of VLM + LLM provides a powerful foundation for creating agents that feel genuinely intelligent.\nThis article is part of my Embodied Intelligence Project. Check out the demos and technical documentation there.\n","permalink":"https://ElijahLiang.github.io/Leiodo-Journey-Development/projects/my-embodied-ai-journey/","summary":"探索具身 AI 的旅程——从启发式方法到视觉语言模型的演进。","title":"具身智能开发之旅：从 Raycast 到 VLM"},{"content":"一、核心命题 1.1 本体论前提 世界是黑盒：世界运作的底层算法不可知。所有物理定律都是对黑盒行为的拟合，而非源码本身。 主体也是黑盒：每个参与者（人、AI、组织、实体）本身也是一个黑盒系统。 黑盒嵌套：黑盒之中有黑盒，层级不可穷尽。 1.2 认识论立场 本体决定，认识不可知：系统可能是决定论的，但信息量超出任何内部观察者的处理能力。 盲人摸象：我们感知到的只是整体动态过程的碎片。 输出是快照：我们所认为的\u0026quot;结果\u0026quot;只是连续动态过程中的一个切片。 二、系统结构 2.1 输入与输出 黑盒接收输入（Input），产生输出（Output） 输入累积：单次输入改变整体轨迹和空间 输出也是过程：输出不是终点，而是下一个输入的起点 2.2 动态交互循环（Dynamic Interaction Loop） S u b j ↑ ← e ← c ← t ← → S h D a y p n e a s m i S c u b I j n e t c e t r a ← c ← t ← i ← o ← n ← ← → ← ← O ← u ← t ← p ← u ← t ← ← / ↓ P a r t o f P r o c e s s 主体与黑盒交互 交互过程产生输出 输出反过来塑造主体 循环持续 2.3 多重黑盒互注 我是黑盒，你是黑盒，世界是黑盒 我们同时向彼此注入 注入的内容在传递过程中变化 没有外部观察者位置——观察本身也是注入 三、系统特性 3.1 演化（Evolution） 系统基于输入而演化 算法本身可以被连接改变（\u0026ldquo;The algorithm can be shaped by connection\u0026rdquo;） 黑盒不是固定的处理器，它在被连接的过程中重写自己 3.2 共振与陷阱（Resonance \u0026amp; Traps） 向量对齐效应：当存在一个足够强且持续的向量时，其他散乱的向量会向其靠拢 共振条件：个人向量的强度 × 与集体潜在势能的对齐程度 陷阱：某些输入模式可能导致系统进入循环或锁死状态 3.3 永恒动态（Eternal Dynamics） 一切都是动态的 \u0026ldquo;固定\u0026quot;只是动态速度极慢的幻觉 系统的某些坐标可能已经趋于稳定（settled），但本质上仍在变化 四、世界功能（World Functions） 黑盒执行三种基本操作：\n连接（Connection）：黑盒之间建立通道 交互（Interaction）：通过通道进行双向注入 传输（Transmission）：信息/能量/意图在系统间流动 五、感知与连接 5.1 感知的性质 感知是对黑盒输出的采样 感知本身受黑盒塑造（五感的欺骗性） 我们永远在系统内部，无法获得全局视角 5.2 连接如何改变系统 黑盒的形状由连接决定，包括其内部算法 新的连接 = 新的算法可能性 当足够多的连接指向同一方向，系统行为会被重新配置 六、关于预测 6.1 未来不可知 未来在认识论上不可推演 信息量如同无法读取的压缩视频字节 预测本身也是输入，会改变系统状态 6.2 但可以影响 虽然不能预测，但可以通过持续、一致的输入来加权系统输出 \u0026ldquo;橙汁比喻\u0026rdquo;：当流入足够多的橙汁，最终味道会被橙汁主导 不是控制结果，而是影响权重 七、开放问题 边界问题：如果主体也是黑盒，主体与世界黑盒的边界在哪里？\n递归问题：如果连接改变算法，什么决定连接如何改变算法？\n观察者悖论：没有外部观察者位置，但理论描述本身预设了一个描述者视角。\n固定与动态的调和：如果一切动态，\u0026ldquo;已稳定的坐标\u0026quot;意味着什么？\n向量强度的定义：什么构成\u0026quot;强\u0026quot;向量？重复？一致性？情感强度？\n八、理论谱系与关联 8.1 与开放剧场理论的关系 开放剧场理论是黑盒系统理论在特定时空切片中的局部实例 开放剧场强调\u0026quot;交互先于参与者\u0026rdquo;——这是黑盒系统在交互层面的表达 剧场是这个黑盒系统中的一个可观察窗口 8.2 与其他框架的对话 控制论（Cybernetics）：反馈循环 复杂系统理论：涌现、自组织 量子力学：观察者效应、测量问题 易经：象的思维、变化为本 现象学：主体间性、生活世界 九、符号说明 Symbol Meaning █ Black Box → Input / Injection Direction ↔ Bidirectional Interaction ? Unknown Output / Algorithm ⟳ Dynamic Loop 框架版本：0.1 状态：初稿，待完善\n","permalink":"https://ElijahLiang.github.io/Leiodo-Journey-Development/knowledge/black-box-system-theory/","summary":"世界是黑盒，主体也是黑盒。探索不可知系统的本体论与认识论框架。","title":"黑盒系统理论 (Black Box System Theory)"},{"content":"概述 这是关于在 NVIDIA DGX Spark (Grace Blackwell) 上进行开发和部署的实践手册。DGX Spark 是 NVIDIA 面向开发者的 AI 超级计算平台。\n目录 硬件与架构认知 网络与代理配置 远程开发环境 AI 大模型部署 Unity ML-Agents 训练流程 Linux 常用生存指令 1. 硬件与架构认知 ARM64 架构注意事项 DGX Spark 使用 ARM64 (aarch64) 架构，与常见的 x86_64 有所不同：\n部分软件包可能没有 ARM 版本 Docker 镜像需要确认架构兼容性 编译时需要指定正确的目标架构 GPU 资源 Blackwell GPU - NVIDIA 最新一代 AI 加速器 支持 FP8、FP16、BF16 等多种精度 大显存支持超大模型部署 2. 网络与代理配置 Proxy Setup # Set proxy environment variables export http_proxy=\u0026#34;http://proxy:port\u0026#34; export https_proxy=\u0026#34;http://proxy:port\u0026#34; export no_proxy=\u0026#34;localhost,127.0.0.1\u0026#34; # Permanent config (add to ~/.bashrc) echo \u0026#39;export http_proxy=\u0026#34;http://proxy:port\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc Docker Proxy Config # Create Docker proxy config mkdir -p ~/.docker cat \u0026gt; ~/.docker/config.json \u0026lt;\u0026lt; EOF { \u0026#34;proxies\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;httpProxy\u0026#34;: \u0026#34;http://proxy:port\u0026#34;, \u0026#34;httpsProxy\u0026#34;: \u0026#34;http://proxy:port\u0026#34; } } } EOF 3. 远程开发环境 VS Code Remote SSH 安装 Remote - SSH 扩展 配置 SSH config： H o s t H U I d o s d g s e e x t r n - N t s a y i p m o t a e u y r r F k y - i o u l u s e r e - r ~ d n / g a . x m s - e s i h p / i d _ r s a 连接并开始开发 JupyterLab # 启动 JupyterLab jupyter lab --ip=0.0.0.0 --port=8888 --no-browser # 或使用 Docker docker run -p 8888:8888 -v $(pwd):/workspace jupyter/pytorch-notebook 4. AI 大模型部署 Deploy with vLLM # Install vLLM pip install vllm # Start model server python -m vllm.entrypoints.openai.api_server \\ --model /path/to/model \\ --host 0.0.0.0 \\ --port 8000 Use Ollama # Install Ollama curl -fsSL https://ollama.com/install.sh | sh # Run model ollama run llama2 5. Unity ML-Agents 训练 Environment Setup # Create conda environment conda create -n mlagents python=3.10 conda activate mlagents # Install ML-Agents pip install mlagents Training Flow # Start training mlagents-learn config/trainer_config.yaml --run-id=experiment_01 # Resume training mlagents-learn config/trainer_config.yaml --run-id=experiment_01 --resume 配置文件示例 behaviors: MyAgent: trainer_type: ppo hyperparameters: batch_size: 1024 buffer_size: 10240 learning_rate: 3.0e-4 network_settings: normalize: true hidden_units: 256 num_layers: 2 max_steps: 500000 6. Linux 常用指令 System Monitor # GPU status nvidia-smi watch -n 1 nvidia-smi # System resources htop free -h df -h Process Management # Run in background nohup python train.py \u0026gt; output.log 2\u0026gt;\u0026amp;1 \u0026amp; # List background jobs jobs -l ps aux | grep python # Kill process kill -9 \u0026lt;PID\u0026gt; File Operations # Find files find . -name \u0026#34;*.py\u0026#34; -type f # Transfer files scp local_file user@dgx:/remote/path/ rsync -avz ./data/ user@dgx:/remote/data/ 常见问题 Q: Docker 拉取镜像失败？ A: 检查代理配置，或使用国内镜像源。\nQ: CUDA 版本不匹配？ A: 使用 nvidia-smi 确认驱动版本，选择兼容的 CUDA 镜像。\nQ: 训练中断后如何恢复？ A: 使用 --resume 参数从 checkpoint 恢复训练。\n持续更新中\u0026hellip;\n","permalink":"https://ElijahLiang.github.io/Leiodo-Journey-Development/projects/dgx-spark-dev/","summary":"在 NVIDIA DGX Spark (Grace Blackwell) 上进行 AI 开发和模型部署的实践经验。","title":"DGX Spark 开发实践手册"},{"content":"项目简介 「边界 / Boundary」是一款 AI 心理健康互动游戏，玩家可以与多个角色进行对话，体验不同的社交场景。项目采用现代全栈技术构建，支持 Web、桌面端（Windows/Mac） 和 移动端（iOS/Android） 多平台运行。\n技术架构图 R C W e o E i a m l n c p e t o ( c / n R t 1 e e r M 8 n a o a t c n c s t + R D T S o e a t u M i e i y F t u C O p l l r e l a S S U w i a r t p / A e I i n m N i a A I e n g e e + - c n k L d w x P i d S a o t S l t r e A y C r . S a o o r P e S k j G t r i v I r S s f d i L E o c ( a 1 x r e L y 4 p m L e o L M r r L a ) t a y y e + e r F A r r n A a i P W m m I e e a b r t R i o B M o u r o n t o t e w i s s o ) e n r 技术栈速查表 领域 技术 用途 前端框架 React 18 UI 组件化开发 元框架 Next.js 14 React 应用框架 类型系统 TypeScript 静态类型检查 样式 Tailwind CSS 原子化 CSS 动画 Framer Motion React 动画库 桌面端 Electron 跨平台桌面应用 移动端 Capacitor 跨平台移动应用 AI API DeepSeek 大语言模型调用 学习路径推荐 建议按照以下顺序学习：\nNode.js 与 npm - 环境搭建 React 基础 - 组件、状态、Hook TypeScript - 类型系统 Next.js - 框架进阶 Tailwind CSS - 样式方案 Electron / Capacitor - 平台打包 项目目录结构 b ├ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ├ │ │ ├ │ ├ ├ ├ └ o ─ ─ ─ ─ ─ ─ ─ u ─ ─ ─ ─ ─ ─ ─ n d s ├ │ │ │ │ ├ │ │ │ ├ │ │ └ p ├ └ e └ p t n t a r ─ ─ ─ ─ u ─ ─ l ─ a a e s r c ─ ─ ─ ─ b ─ ─ e ─ c i x c y / l c k l t o - a ├ ├ ├ └ c ├ ├ └ l ├ └ t └ i a b t m a w . n p p ─ ─ ─ ─ o ─ ─ ─ i ─ ─ y ─ c a r a g i c f r p ─ ─ ─ ─ m ─ ─ ─ b ─ ─ p ─ / a c o i e n o i o / p e t k n n . d n g j a p l g o S C c a s g a g / . j . f . e p a a l n t h h i / a r r j s c i j c i g y o e a a a E m s s o o g s t / e o b n r t r n e u n n . o / c . u a t t I a g . n f j n h t t l s S n c i t d i s a s . s c p t n s s g t x t . r u e e / . / s c e t r . j x s e . s t s s n t . s . s t t x s s # # # # x # # # # # # # # # A M R G # # # # # # N P a o l R U C A T C B S e I i o o e t h I y S h a E P T N T o x n t b a i a p t a c l r a e y u t r a c l r e e a r k e o i x p r . o p l l t i a n S t a g c j l t e c j u a a t c g c i c r t e w . S e s t g y s c i t i r c t o r c i j c e e o t o e e n i e u o t n s r c A s u y m s r e p a r n n d i o p t l p t s d c c p d p ( e o a d s a m o c o t e b s n n e t e v i a n o n R a e d f y t a m i f n f c o c n i p s t a n i f i o u k t c n e a g g i g n t e s o i s r e p g f e n n t s s r i r d f i o g ) i o c p g n e a s s g s e s 核心技术要点 React Component Design // Function Component + Hooks const ChatMessage: React.FC\u0026lt;MessageProps\u0026gt; = ({ content, role }) =\u0026gt; { const [isTyping, setIsTyping] = useState(false); useEffect(() =\u0026gt; { // Typewriter effect }, [content]); return ( \u0026lt;motion.div initial={{ opacity: 0, y: 20 }} animate={{ opacity: 1, y: 0 }} \u0026gt; {content} \u0026lt;/motion.div\u0026gt; ); }; AI API Integration // DeepSeek API call const response = await fetch(\u0026#39;/api/chat\u0026#39;, { method: \u0026#39;POST\u0026#39;, body: JSON.stringify({ messages: conversationHistory, character: currentCharacter, }), }); 关键收获 组件化思维 - 将 UI 拆分为可复用的独立单元 类型安全 - TypeScript 让大型项目更易维护 跨平台策略 - 一套代码，多端部署 AI 集成 - LLM API 的最佳实践 项目持续迭代中\u0026hellip;\n","permalink":"https://ElijahLiang.github.io/Leiodo-Journey-Development/projects/boundary-tech-stack/","summary":"AI 心理健康互动游戏的全栈技术架构，支持 Web、桌面端和移动端多平台。","title":"边界 / Boundary 项目技术栈"},{"content":"核心问题 当面对复杂系统时，我们常常陷入决策瘫痪的困境。这个问题的本质可以用以下链条来描述：\n变量多 → 状态空间指数增长 → 熵增 → 决策瘫痪\n在一个包含 n 个变量的系统中，如果每个变量有 2 种可能状态，整个系统的状态空间就会达到 2^n。当变量数量增加时，这种指数级增长会迅速让系统变得不可控。\n五大核心策略 1. 识别关键变量（减少自由度） 并非所有变量都同等重要。通过识别真正影响系统行为的关键变量，我们可以大幅减少需要关注的自由度。\n实践方法：\n使用帕累托原则（80/20 法则） 进行敏感性分析 识别瓶颈和杠杆点 2. 建立约束条件（缩小状态空间） 通过设定合理的约束条件，可以将无限的可能性压缩到可管理的范围内。\n实践方法：\n设定明确的边界条件 定义可接受的范围 建立优先级规则 3. 分治拆解（化整为零） 将大问题分解为相对独立的小问题，使每个子问题都处于可控范围内。\n实践方法：\n模块化设计 层次化分解 识别子系统之间的接口 4. 序列化处理（一次只关注一个） 人类的工作记忆容量有限（通常为 7±2 个项目）。通过序列化处理，我们可以将注意力集中在单一维度上。\n实践方法：\n建立处理队列 使用时间盒（timeboxing） 单任务专注 5. 外部化存储（减轻工作记忆） 将信息从大脑转移到外部系统，释放认知资源用于思考和决策。\n实践方法：\n使用笔记系统（如 Obsidian） 建立知识库 创建检查清单和流程图 效果对比 维度 处理前 处理后 复杂度 指数复杂度 O(2^n) 线性复杂度 O(n) 可控性 不可控 可控 认知负荷 超载 适中 决策效率 瘫痪 流畅 数学原理 原始状态空间：S = 2^n（n 个二值变量）\n应用策略后：\n识别关键变量：n → k（k \u0026laquo; n） 建立约束：减少每个变量的可能值 分治拆解：S = m × 2^(n/m)（m 个子系统） 熵降低：ΔS = log₂(2^n) - log₂(m × 2^(n/m)) = n - log₂m - n/m\n当 m 足够大时，熵显著降低，系统变得可管理。\n实践案例 案例 1：项目管理 问题：一个包含 20 个功能点的项目，每个功能有多种实现方式。\n应用策略：\n识别核心功能（MVP）：20 → 5 个关键功能 建立约束：技术栈限定为已掌握的工具 分治：按模块拆分（前端/后端/数据库） 序列化：先完成核心流程，再优化细节 外部化：使用看板管理任务 结果：从不知如何开始 → 清晰的执行路径\n案例 2：知识管理 问题：海量信息输入，无法有效组织和检索。\n应用策略：\n识别关键主题：建立核心标签体系 建立约束：只记录可执行的知识 分治：按领域建立文件夹结构 序列化：每次只处理一个主题 外部化：使用 Obsidian 双向链接 结果：从信息过载 → 结构化知识网络\n延伸阅读 《系统思考》- Peter Senge 《复杂》- Melanie Mitchell 《Getting Things Done》- David Allen 最后更新：2025-11-22\n","permalink":"https://ElijahLiang.github.io/Leiodo-Journey-Development/knowledge/chaos-system-management/","summary":"面对复杂系统时如何避免决策瘫痪？五大核心策略将指数复杂度降至线性。","title":"混沌系统管理方法"}]